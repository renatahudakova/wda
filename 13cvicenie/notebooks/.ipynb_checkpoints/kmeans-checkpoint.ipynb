{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práca s algoritmom K-Means\n",
    "\n",
    "na tomto príklade si ukážeme prácu s algoritmom K-Means na jednoduchom príklade. \n",
    "\n",
    "Ukážeme si vytvorenie zhlukovacieho modelu na dátach, ktoré popisujú klientov veľkoobchodného predajcu. Pozostáva z informácií, ktoré charakterizujú ročné nákupy čerstvých, mliečnych, potravinových a iných produktov. Každý klient je popísaný nasledovnými atribútmi:\n",
    "* Fresh - ročné výdajne na čerstvé produkty \n",
    "* Milk - ročné výdajne na mliečne produkty\n",
    "* Grocery - ročné výdajne na potravinové produkty\n",
    "* Frozen - ročné výdajne na mrazené produkty \n",
    "* Detergents_Paper - ročné výdajne na čistiace a papierové produkty\n",
    "* Delicassen - ročné výdajne na delikatesy\n",
    "* Channel - spôsob predaja zákazníkom hotnoty - Horeca (Hotel/Restaurant/Cafe) alebo Retail\n",
    "* Region - nominálne hodnoty, zodpovedajú Lisbon, Porto alebo Other\n",
    "\n",
    "Cieľom je vytvoriť zhlukovací model, ktorý by našiel v množine skupiny rôznych typov zákazníkov.\n",
    "\n",
    "Najprv importujeme potrebné knižnice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načítame dáta zo súboru do dátového rámca a vypíšeme hlavičku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/wholesale.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keďže dataset obsahuje 2 kategorické atribúty (Channel a Region), tieto stĺpce transformujeme pomocou One Hot Encoder prístupu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['Channel', 'Region']) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V prípade zhlukovania pomocou K-Means je veľmi podstatnou časťou výpočet vzdialeností jednotlivých príkladov od centier zhlukov. Aby sme zabezpečili rovnakú dôležitosť všetkých atribútov, tak ich normalizujeme na rovnaký rozsah. Podobne ako pri klasifikácii môžeme použiť `MinMaxScaler`, na celý dátový rámec (normalizujeme všetky atribúty).\n",
    "\n",
    "Môžeme pretransformovať normalizované dáta do dátového rámca (ale nemusíme, ďalšie funkcie môžu pracovať s numpy poľom, ktoré dostaneme na výstupe normalizácie). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # importujeme MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() # Inicializujeme transformátor\n",
    "scaler.fit(data) # aplikujeme ho na vstupné dáta\n",
    "\n",
    "# po aplikovaní scaleru budeme mať výstup vo forme numpy poľa\n",
    "# to môžeme - ale nemusíme - naspať transformovať do pandas rámca (ak chceme ešte robiť nejaké predspracovanie)\n",
    "# funkcie pre trénovanie modelov potom vedia pracovať aj s pandas aj s numpy\n",
    "\n",
    "# data_norm = scaler.transform(data)\n",
    "data_norm = pd.DataFrame(scaler.fit_transform(data), index=data.index, columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz vytvoríme K-Means zhlukovací model, ktorý natrénujeme na vstupných dátach. Implementácia K-Means v Sciki-learn umožňuje nasledovné nastavenia algoritmu (vybrali sme iba niektoré):\n",
    "* n_clusters - zodpovedá hodnote parametra `k`, definuje počet zhlukov\n",
    "* max_iter - zodpovedá maximálnemu počtu iterácií algoritmu (defaultná hodnota - 300)\n",
    "\n",
    "Ako výstup po vytvorení modelu môžeme použiť:\n",
    "* cluster_centers_ - pole súradníc centroidov pre jednotlivé zhluky\n",
    "* labels_ - príslušnosť k zhlukom pre všetky objekty vstupných dát\n",
    "* inertia_ - suma štvorcov vzdialeností príkladov k centroidu (kritérium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=4)\n",
    "model.fit(data_norm)\n",
    "# labels = model.predict(data_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Môžeme teraz vypísať napr. sumu štvorcov vzdialeností v rámci zhlukov pre vytvorený model alebo napr. spočítať vzdialenosti medzi jednotlivými centroidmi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances # importujeme funkciu euclidean_distances ktorá nám spočíta vzdialenosti medzi zadanými bodmi\n",
    "\n",
    "print(\"Inertia:\") # zobrazíme vypočítanú inertiu\n",
    "print(model.inertia_)\n",
    "\n",
    "print(\"Vzajomne vzdialenosti centroidov:\")\n",
    "dists = euclidean_distances(model.cluster_centers_) # spočítame vzdialenosti medzi centrami zhlukov a vypíšeme ich\n",
    "print(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takisto sa vieme pozrieť na obsah jednotlivých zhlukov. Pomocou `model.labels_` sa vieme pozrieť na to, do ktorých zhlukov model pridelil jednotlivé príklady zo vstupnej množiny dát. Môžeme sa takisto pozrieť na konkrétny zhluk a príklady, ktoré doň patria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Príklady a ich príslušnosť do zhlukov:\")\n",
    "print(model.labels_) # vypíšeme príslušnost k zhluku pre každý príklad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Príklady zo zhluku 0:\")\n",
    "cluster_0 = np.where(model.labels_==0) # vyberieme len príklady, ktoré patria do zhluku 0\n",
    "print(cluster_0) # vypíšeme ich na obrazovku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz si ukážeme ako môžeme porovnať dva zhluky navzájom. \n",
    "\n",
    "Vytvorím si teraz dátové rámce (nenormalizované) z príkladov pre jednotlivé zhluky. Teraz sa môžem pozrieť na obsah jednotlivých zhlukov a porovnať ich spoločné vlastnosti alebo rozdiely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1 = np.where(model.labels_==1) # nájdeme príklady priradené do zhluku 1\n",
    "\n",
    "data_cluster_0 = data.iloc[cluster_0] # dátový rámec z príkladov pre zhluk 0\n",
    "data_cluster_1 = data.iloc[cluster_1] # dátový rámec z príkladov pre zhluk 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cluster_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cluster_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na porovnanie zhlukov môžeme robiť aj vizualizácie pomocou Seaborn.\n",
    "\n",
    "### Úloha\n",
    "\n",
    "Vizualizujte pomocou Seaborn napr.: \n",
    "* Distribúcie hodnôt zvolených atribútov pre jednotlivé zhluky\n",
    "* Priemery hodnôt zvolených atribútov jednotlivých zhlukov  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako nájsť najlepšiu hodnotu počtu zhlukov? Môžeme použiť tzv. \"elbow\" metódu. Podobne ako pri Grid Search vytvoríme množinu modelov s rôznymi hodnotami parametra. Avšak v tomto prípade budeme potrebovať aj nejaké kritérium, ktoré by nám niečo povedalo o samotných zhlukoch. \n",
    "\n",
    "Keďže používame model K-Means, môžeme hľadať optimálny počet zhlukov tak, že budeme pre jednotlivé modely počítať sumu štvorcov vzdialeností príkladov zatriedených do zhluku k ich centroidu. Túto hodnotu vieme z modelu získať ako jeden z jeho "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_of_squared_distances = [] # prázdne pole stvorcov vzdialeností\n",
    "\n",
    "K = range(1,15) # vygeneruje rozsah parametrov K\n",
    "\n",
    "# v cykle vytboríme modely s rôznymy nastaveniami\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(data_norm)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "print(Sum_of_squared_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Môžeme vizializovať závislosť počtu zhlukov od ich \"kompaktnosti\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Pocet zhlukov')\n",
    "plt.ylabel('Suma stvorcov vzdialenosti')\n",
    "plt.title('Hladanie optimalneho poctu zhlukov')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
